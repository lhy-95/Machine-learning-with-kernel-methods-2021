{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import  tqdm\n",
    "\n",
    "\n",
    "def load_data(dataset, train = True):\n",
    "    \n",
    "    if train:\n",
    "        df_Xtr = pd.read_csv(f'dataset/Xtr{dataset}.csv', index_col=0)   # read training X\n",
    "        df_Ytr = pd.read_csv(f'dataset/Ytr{dataset}.csv')  # read training y\n",
    "        \n",
    "        X = np.array(df_Xtr).squeeze()\n",
    "        Y = df_Ytr.Bound.values.ravel().astype(float)\n",
    "        \n",
    "    else:\n",
    "        df_Xte = pd.read_csv(f'dataset/Xte{dataset}.csv', index_col=0)   # read test X\n",
    "        X = np.array(df_Xte).squeeze()\n",
    "        Y = None\n",
    "    \n",
    "    return X, Y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct dictionary and the gram matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dic_constr(X, k):\n",
    "    Subseqs_dic ={}\n",
    "    \n",
    "    for idx, fulseq in enumerate(X):\n",
    "        # compute all its subsequences\n",
    "        subseqs = [ fulseq[i:i + k]  for i in range(len(fulseq) - k + 1)  ]\n",
    "        \n",
    "        for subseq in subseqs:\n",
    "            # creat a new dict for new subsequences\n",
    "            if not subseq in Subseqs_dic:\n",
    "                Subseqs_dic[subseq] = {}\n",
    "            if not str(idx) in Subseqs_dic[subseq]:\n",
    "                Subseqs_dic[subseq][str(idx)] = 0\n",
    "            \n",
    "            Subseqs_dic[subseq][str(idx)] += 1\n",
    "                    \n",
    "    return Subseqs_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(dicS, dicT, nrow, ncol):\n",
    "    # dicS : always the training dictionary\n",
    "    # dicT : test dictionary (could be the test set)\n",
    "    # nrow : size of test set (could be the training set)\n",
    "    # ncol : always size of training set\n",
    "    #import time\n",
    "    gram_mat = np.zeros((nrow,ncol))\n",
    "    \n",
    "    #start = time.time()\n",
    "    for subseqT, subdicT in dicT.items():\n",
    "        if subseqT in dicS.keys():\n",
    "            subdicS = dicS[subseqT]\n",
    "            for i, numi in subdicT.items():\n",
    "                for j, numj in subdicS.items():\n",
    "                    gram_mat[int(i),int(j)] += numi * numj   \n",
    "                    \n",
    "    #stop = time.time()\n",
    "    #print('\\t time {:.4f}'.format(stop - start))\n",
    "    \n",
    "    return gram_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mismath kenel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_neibor(st): \n",
    "    neibor = []\n",
    "    for i in range(len(st)):\n",
    "        for new_c in 'AGCT':\n",
    "            if new_c == st[i]:\n",
    "                continue\n",
    "            new_st = st[:i]+new_c+st[i+1:]\n",
    "            neibor.append(new_st)\n",
    "    return neibor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_mismatch_matrix(dicS, dicT, nrow, ncol, w=0.3):\n",
    "    # dicS : always the training dictionary\n",
    "    # dicT : test dictionary (could be the test set)\n",
    "    # nrow : size of test set (could be the training set)\n",
    "    # ncol : always size of training set\n",
    "    import time\n",
    "    start = time.time()\n",
    "    gram_mat = gram_matrix(dicS, dicT, nrow, ncol)\n",
    "    \n",
    "    for subseqT, subdicT in tqdm(dicT.items()):\n",
    "        for misone in str_neibor(subseqT):\n",
    "            if misone in dicS:\n",
    "                subdicS = dicS[misone]\n",
    "                for i, numi in subdicT.items():\n",
    "                    for j, numj in subdicS.items():\n",
    "                        gram_mat[int(i),int(j)] += w * numi * numj\n",
    "                   \n",
    "    stop = time.time()\n",
    "    print('\\t time {:.4f}'.format(stop - start))\n",
    "    \n",
    "    return gram_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(y):\n",
    "    return 2*y-1\n",
    "\n",
    "def binary(y):\n",
    "    return ((y + 1) / 2).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM solution\n",
    "from cvxopt import solvers, matrix\n",
    "\n",
    "def SVM(K, y, lbd=1):\n",
    "#     print(lbd)\n",
    "    y = sign(y)  # {0,1} to {-1,1}\n",
    "    n = len(y)\n",
    "    \n",
    "    q = - 2 * y\n",
    "    P = 2 * K\n",
    "    G = np.zeros((2*n, n))\n",
    "    G[:n, :] = - np.diag(y)\n",
    "    G[n:, :] = np.diag(y)\n",
    "    h = np.zeros(2 * n)\n",
    "    h[n:] = 1 / (2 * lbd * n)\n",
    "    \n",
    "    P = matrix(P)\n",
    "    q = matrix(q)\n",
    "    G = matrix(G)\n",
    "    h = matrix(h)\n",
    "\n",
    "    solvers.options['show_progress'] = False\n",
    "    alpha = solvers.qp(P, q, G, h)\n",
    "\n",
    "    return alpha\n",
    "\n",
    "def predict(K, alpha):\n",
    "    return binary(np.sign(K@alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply SVM on data and do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = {'0': [8 ,0.1], '1':[8, 0.1], '2':[8,0.01]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the training gram matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7556d6ff2b74a8fa23ffa39631df882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t time 21.1899\n",
      "Compute the testing gram matrix...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b210b2500b04ae2af433664b2f4ec21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38576 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t time 10.3946\n",
      "Length of subsequence is : 8, and the accuracy on training set is 0.8865\n"
     ]
    }
   ],
   "source": [
    "dataset = ['1']\n",
    "pre_y = []\n",
    "for set in dataset:\n",
    "    Xtr, Ytr = load_data(set,train =True)\n",
    "    Xte,_ = load_data(set,train = False)\n",
    "\n",
    "    # length of subsequence\n",
    "    k = paras[set][0]\n",
    "    lbd = paras[set][1]\n",
    "    \n",
    "    dic_tr = dic_constr(Xtr, k)\n",
    "    dic_te = dic_constr(Xte, k)\n",
    "\n",
    "    len_tr, len_te = len(Xtr), len(Xte)\n",
    "\n",
    "    # the gram matrix \n",
    "    print('Compute the training gram matrix...')\n",
    "    gram_mat_train = gram_mismatch_matrix(dic_tr,dic_tr, len_tr,len_tr)\n",
    "    print('Compute the testing gram matrix...')\n",
    "    gram_mat_test = gram_mismatch_matrix(dic_tr, dic_te, len_te,len_tr)\n",
    "\n",
    "    # SVM solution\n",
    "    sol = SVM(gram_mat_train, Ytr,lbd)\n",
    "    pred_train = predict(gram_mat_train, sol['x'])\n",
    "    acc_train = np.sum(np.abs(pred_train.squeeze() - Ytr)) / len_tr\n",
    "    acc_train = 1-acc_train\n",
    "    print('Length of subsequence is : {:}, and the accuracy on training set is {:.4f}'.format(k, acc_train))\n",
    "\n",
    "    # output on the test set\n",
    "    pred_test = predict(gram_mat_test, sol['x'] ).squeeze()\n",
    "    pre_y.append(pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concate with the results of `spectrum kernel_normalized.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred = []\n",
    "new_pred.append(np.load('pred_normal_0.npy'))\n",
    "new_pred.append(pre_y[0])\n",
    "new_pred.append(np.load('pred_normal_2.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = np.array(new_pred).reshape(3000)\n",
    "pred = pd.Series(pred_all.astype('int'), name=\"Bound\")\n",
    "pred.index = pd.Series(np.arange(len(pred_all)), name=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('Yte.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
